---
title: "Durable Streams: Java로 구현한 실시간 동기화 프로토콜"
description: "Durable Streams 프로토콜의 Java 구현체를 만들고 Maven Central에 퍼블리싱하기까지의 여정을 다룹니다."
date: 2026-02-12
category: "project"
tags: ["java", "reactive", "maven-central", "spring-webflux", "micronaut", "protocol"]
draft: true
publish: false
---

## 프로젝트 소개

[Durable Streams](https://github.com/durable-streams/durable-streams)는 클라이언트 애플리케이션에 대한 실시간 동기화를 위한 open protocol이다. HTTP 위에서 동작하며, catch-up read, long-poll, SSE(Server-Sent Events) 세 가지 모드를 통해 스트림 데이터를 안정적으로 전달한다. 기존의 WebSocket이나 독자적인 실시간 프로토콜과 달리, 표준 HTTP 인프라(CDN, 로드밸런서, 프록시)와 완전히 호환되는 것이 핵심 특징이다.

[durable-streams-java](https://github.com/Clickin/durable-streams-java)는 이 프로토콜의 Java 17+ 구현체로, JDK 21의 Virtual Threads를 활용한 고성능 파일 기반 스토리지, 5개 프레임워크 통합 어댑터, 그리고 conformance suite 131개 테스트 전체 통과를 목표로 개발했다.

## 모듈 구조

프로젝트는 11개의 퍼블리싱 모듈과 6개의 내부 모듈로 구성된다.

```
durable-streams-java/
  durable-streams-core           # 프로토콜 타입, Offset, Headers, StreamEvent
  durable-streams-client          # JDK HttpClient 기반 클라이언트
  durable-streams-json-spi        # JSON 직렬화 SPI (라이브러리 비의존)
  durable-streams-json-jackson    # Jackson 구현체
  durable-streams-server-spi      # 서버 스토리지/정책 추상화
  durable-streams-server-core     # 프로토콜 엔진 + 파일 스토어
  durable-streams-servlet         # Servlet 통합 (Spring MVC)
  durable-streams-spring-webflux  # Spring WebFlux 통합
  durable-streams-micronaut       # Micronaut 통합
  durable-streams-quarkus         # Quarkus 통합
  durable-streams-ktor            # Ktor 통합
  ---
  durable-streams-conformance-runner  # conformance 테스트 러너 (비퍼블리싱)
  example-spring-webflux (4433)       # 프레임워크별 예제 앱
  example-spring-webmvc  (4434)
  example-micronaut      (4431)
  example-quarkus        (4432)
  example-ktor           (4435)
```

모듈 간 의존 관계는 명확한 계층을 따른다:

```
[core] <-- [json-spi] <-- [json-jackson]
  ^            ^
  |            |
[server-spi] --+-- [server-core] <-- [servlet]
                                 <-- [spring-webflux]
                                 <-- [micronaut]
                                 <-- [quarkus]
                                 <-- [ktor]
[core] <-- [client]
```

`server-spi`는 `StreamStore`, `CursorPolicy`, `RateLimiter` 같은 인터페이스만 정의하고, 실제 구현은 `server-core`에 둔다. 프레임워크 어댑터 모듈은 `server-core`의 `DurableStreamsHandler`를 각 프레임워크의 HTTP 추상화에 연결하는 얇은 레이어 역할만 수행한다.

## 프로토콜 구현 핵심

### StreamStore SPI

프로토콜의 핵심은 `StreamStore` 인터페이스다. 스트림의 CRUD와 await(변경 대기)를 정의한다:

```java
public interface StreamStore {
    CreateOutcome create(URI url, StreamConfig config, InputStream initialBody) throws Exception;
    AppendOutcome append(URI url, String contentType, String streamSeq, InputStream body) throws Exception;
    boolean delete(URI url) throws Exception;
    Optional<StreamMetadata> head(URI url) throws Exception;
    ReadOutcome read(URI url, Offset startOffset, int maxBytesOrMessages) throws Exception;
    boolean await(URI url, Offset startOffset, Duration timeout) throws Exception;
}
```

이 인터페이스는 의도적으로 blocking으로 설계했다. Reactive나 coroutine 동작은 각 프레임워크 통합 레이어에서 적절한 executor/scheduler 위에 실행하면 되기 때문이다. 단일 인터페이스를 모든 프레임워크에서 공유할 수 있어 구현 중복이 없다.

### DurableStreamsHandler

프레임워크에 비의존적인 HTTP 핸들러가 프로토콜의 모든 로직을 담당한다:

```java
DurableStreamsHandler handler = DurableStreamsHandler.builder(new InMemoryStreamStore())
    .cursorPolicy(new CursorPolicy(Clock.systemUTC()))
    .cachePolicy(CachePolicy.defaultPrivate())
    .longPollTimeout(Duration.ofSeconds(25))
    .sseMaxDuration(Duration.ofSeconds(60))
    .build();
```

`handle(ServerRequest)` 메서드 하나로 PUT(create), POST(append), GET(read/long-poll/SSE), HEAD(metadata), DELETE를 모두 처리한다. `ServerRequest`와 `ServerResponse`는 프레임워크 비의존적인 단순 record/class이므로, 어댑터는 프레임워크의 request/response를 이 타입으로 변환하기만 하면 된다.

### Offset과 Lexicographic Encoding

Durable Streams 프로토콜에서 offset은 opaque string이다. 클라이언트는 offset의 내부 형식을 알 필요가 없고, 서버가 반환한 값을 그대로 다음 요청에 전달하면 된다. 단, offset은 lexicographic order로 정렬 가능해야 한다.

```java
public final class Offset implements Comparable<Offset> {
    private final String value;

    public static Offset beginning() {
        return new Offset(Protocol.OFFSET_BEGINNING); // "-1"
    }

    @Override
    public int compareTo(Offset o) {
        return this.value.compareTo(o.value);
    }
}
```

내부적으로는 `LexiLong` 인코딩을 사용한다. 파일의 byte offset(long)을 lexicographic order가 보장되는 문자열로 변환하는 방식이다. 이렇게 하면 byte 단위의 정확한 위치 추적이 가능하면서도 프로토콜의 opaque offset 요구사항을 만족한다.

### StreamEvent: Sealed Interface

클라이언트/서버 간에 주고받는 이벤트는 Java 17의 sealed interface로 모델링했다:

```java
public sealed interface StreamEvent
    permits StreamEvent.Data, StreamEvent.Control, StreamEvent.UpToDate {

    record Data(ByteBuffer bytes, String contentType) implements StreamEvent {}
    record Control(Offset streamNextOffset, Optional<String> streamCursor) implements StreamEvent {}
    record UpToDate(Offset nextOffset) implements StreamEvent {}
}
```

`Data`는 실제 페이로드, `Control`은 SSE 모드에서 다음 offset과 cursor 정보를 전달하는 신호, `UpToDate`는 클라이언트가 스트림의 최신 상태까지 따라잡았음을 알리는 신호다. sealed interface 덕분에 pattern matching에서 모든 케이스를 컴파일 타임에 보장할 수 있다.

## Virtual Threads와 파일 스토리지

### 왜 Virtual Threads + Blocking I/O인가

프로젝트 초기에 세 가지 스토리지 방식을 벤치마크했다:

| 워크로드 | Blocking I/O | NIO Async | Virtual Threads |
|----------|-------------|-----------|-----------------|
| Sequential writes | Baseline | Slower (callback overhead) | Baseline 수준 |
| Sequential reads | Baseline | Slower | Baseline 수준 |
| Concurrent reads | Baseline | 1.08x | **1.33x** |
| Mixed (70R/30W) | Baseline | Equivalent | Equivalent |

Java의 `AsynchronousFileChannel`은 실제로는 내부 thread pool에서 blocking I/O를 수행하고 callback으로 감싸는 방식이다. OS 레벨에서 진정한 async file I/O를 제공하지 않기 때문이다(Linux의 io_uring 이전). 결국 양쪽 다 thread를 사용하지만, Virtual Threads는 callback 복잡성 없이 더 나은 성능을 보였다.

### BlockingFileStreamStore 구현

파일 기반 스토어의 핵심 설계 결정은 세 가지다:

**Per-stream ReentrantLock**: 스트림별로 독립적인 lock을 사용해 다른 스트림의 쓰기가 서로를 차단하지 않는다.

```java
private final ConcurrentHashMap<URI, ReentrantLock> writeLocks = new ConcurrentHashMap<>();

// append 시
ReentrantLock lock = writeLocks.computeIfAbsent(url, k -> new ReentrantLock());
lock.lock();
try {
    // ... atomic append + metadata update
} finally {
    lock.unlock();
}
```

**Lock-free await queue**: long-poll/SSE 대기 중인 수천 개의 연결은 `ConcurrentLinkedQueue<CompletableFuture<Boolean>>`으로 관리한다. 새 데이터가 append되면 queue의 모든 waiter를 깨운다:

```java
private final ConcurrentHashMap<URI, ConcurrentLinkedQueue<CompletableFuture<Boolean>>> awaiters
    = new ConcurrentHashMap<>();

private void notifyWaiters(URI url) {
    ConcurrentLinkedQueue<CompletableFuture<Boolean>> queue = awaiters.get(url);
    if (queue != null) {
        CompletableFuture<Boolean> f;
        while ((f = queue.poll()) != null) {
            f.complete(true);
        }
    }
}
```

**RocksDB 메타데이터**: 스트림 데이터는 파일에, 메타데이터(config, offset, TTL)는 RocksDB에 저장한다. `SharedMetadataStore` 패턴으로 동일 디렉토리에 대해 RocksDB 인스턴스를 공유하여 리소스 누수를 방지한다.

### Virtual Thread Executor Fallback

Java 17 환경에서도 동작하도록 reflection을 통해 Virtual Thread 지원 여부를 감지한다:

```java
static ExecutorService newExecutor(String namePrefix) {
    try {
        Method method = Executors.class.getMethod("newVirtualThreadPerTaskExecutor");
        return (ExecutorService) method.invoke(null);
    } catch (Exception ignored) {
        return Executors.newCachedThreadPool(new NamedThreadFactory(namePrefix));
    }
}
```

JDK 21+에서는 Virtual Thread executor가, 17~20에서는 cached thread pool이 사용된다.

## 프레임워크 통합

5개 프레임워크 어댑터는 모두 동일한 패턴을 따른다: 프레임워크의 request를 `ServerRequest`로 변환하고, `DurableStreamsHandler.handle()`을 호출한 뒤, `ServerResponse`를 프레임워크의 response로 변환한다.

### Spring WebFlux 예시

```java
@Configuration
public class RouterConfig {
    @Bean
    public RouterFunction<ServerResponse> durableStreamsRoutes(
            DurableStreamsWebFluxAdapter adapter) {
        return RouterFunctions.route()
            .add(RouterFunctions.route(req -> true, adapter::handle))
            .build();
    }
}
```

### Quarkus (RESTEasy Reactive) 예시

```java
@Path("/")
public class DurableStreamsResource {
    @GET @Path("{path:.*}")
    public Response get(@Context UriInfo uriInfo, @Context HttpHeaders headers) {
        return DurableStreamsQuarkusAdapter.handle(
            HttpMethod.GET, uriInfo, headers, null, handler);
    }
    // POST, PUT, DELETE, HEAD도 동일 패턴
}
```

### Ktor 예시 (Kotlin)

```kotlin
fun Application.module() {
    val handler = DurableStreamsHandler.builder(InMemoryStreamStore())
        .cursorPolicy(CursorPolicy(Clock.systemUTC()))
        .build()

    routing {
        route("{path...}") {
            handle { DurableStreamsKtorAdapter.handle(call, handler) }
        }
    }
}
```

어댑터의 코드량은 프레임워크당 하나의 클래스, 수십 줄 수준이다. 프로토콜 로직은 전부 `DurableStreamsHandler`에 있으므로, 새로운 프레임워크를 추가할 때 프로토콜을 다시 구현할 필요가 없다.

## Conformance Suite 통과

Durable Streams 프로토콜은 공식 conformance test suite를 제공한다. Node.js로 작성된 테스트 러너가 서버/클라이언트 구현체를 검증한다. GitHub Actions CI에서 7개 대상에 대해 conformance test를 수행한다:

- InMemory server (기본)
- File-based server (BlockingFileStreamStore)
- Quarkus example app
- Micronaut example app
- Spring WebFlux example app
- Spring WebMVC example app
- Ktor example app

각 프레임워크 예제 앱은 고유한 포트(4431~4435)로 실행되며, Node.js 테스트 러너가 프로토콜 적합성을 검증한다. 결과는 **131/131 테스트 통과**다.

Conformance 과정에서 발견한 주요 이슈들:

- **Quarkus의 느린 startup**: GitHub Actions에서 startup 시간이 40초를 초과하는 경우가 있어 timeout을 여유 있게 설정해야 했다
- **Spring WebFlux/WebMVC의 SSE 응답 형식**: SSE frame의 줄바꿈 처리에서 프레임워크별 미묘한 차이가 있었다
- **Micronaut의 byte[] body handling**: request body를 byte[]로 바인딩할 때 Content-Type 미스매치 이슈가 있었다

## Maven Central Portal 마이그레이션

### OSSRH 종료 대응

2025년 6월 30일부로 OSSRH(Sonatype OSS Repository Hosting)가 sunset되었다. 기존에는 `s01.oss.sonatype.org`에 staging 후 release하는 방식이었지만, 이제는 [Maven Central Portal](https://central.sonatype.com/)을 통해야 한다.

패키지 네임스페이스도 `io.durablestreams`에서 `io.github.clickin`으로 마이그레이션했다. Maven Central Portal은 GitHub 계정 기반의 네임스페이스 검증을 지원하므로, `io.github.clickin` 네임스페이스를 사용하면 별도의 도메인 인증 없이 퍼블리싱할 수 있다.

### nmcp 설정 플러그인

Maven Central Portal 퍼블리싱에는 [`com.gradleup.nmcp`](https://github.com/GradleUp/nmcp) Gradle 플러그인을 사용한다:

```kotlin
// settings.gradle.kts
plugins {
    id("com.gradleup.nmcp.settings") version "1.4.3"
}

nmcpSettings {
    centralPortal {
        username.set(System.getenv("CENTRAL_PORTAL_USERNAME"))
        password.set(System.getenv("CENTRAL_PORTAL_PASSWORD"))
        publishingType.set("USER_MANAGED")
    }
}
```

settings plugin으로 적용하면 `maven-publish`가 설정된 모든 서브프로젝트에 자동으로 nmcp가 연결된다. `USER_MANAGED` 모드는 Portal에 업로드 후 수동으로 release 버튼을 누르는 방식이고, CI 릴리스 워크플로에서는 `AUTOMATIC`으로 전환한다.

### 퍼블리싱 모듈 선별

11개 모듈만 Maven Central에 퍼블리싱하고, conformance runner와 example 앱 6개는 제외한다:

```kotlin
// build.gradle.kts
val publishableProjects = setOf(
    "durable-streams-core",
    "durable-streams-client",
    "durable-streams-json-spi",
    "durable-streams-json-jackson",
    "durable-streams-server-spi",
    "durable-streams-server-core",
    "durable-streams-servlet",
    "durable-streams-spring-webflux",
    "durable-streams-micronaut",
    "durable-streams-quarkus",
    "durable-streams-ktor"
)

subprojects {
    if (publishableProjects.contains(project.name)) {
        apply(plugin = "maven-publish")
        apply(plugin = "signing")
        // ... POM 메타데이터, 서명 설정
    }
}
```

## GPG 서명 및 퍼블리싱 워크플로우

### In-Memory PGP Signing

Maven Central은 모든 artifact에 GPG 서명을 요구한다. CI 환경에서는 키 파일을 디스크에 두지 않고, GitHub Secrets에 저장된 ASCII-armored private key를 Gradle의 `useInMemoryPgpKeys`로 직접 전달한다:

```kotlin
configure<SigningExtension> {
    val signingKey = System.getenv("SIGNING_KEY")
    val signingPassword = System.getenv("SIGNING_PASSWORD")
    if (signingKey != null && signingPassword != null) {
        useInMemoryPgpKeys(signingKey, signingPassword)
        sign(the<PublishingExtension>().publications["mavenJava"])
    }
}
```

### CI/CD 파이프라인

두 개의 워크플로가 퍼블리싱을 지원한다:

**publish-dryrun.yml** - 모든 push/PR에서 실행. local Maven repository에 퍼블리싱한 뒤, 11개 모듈이 모두 존재하고 6개 제외 모듈이 없는지 검증한다.

**release.yml** - `v*` 태그 push 시 트리거. 태그 이름에서 버전을 추출하고, 서명된 artifact을 Maven Central Portal에 업로드한다:

```bash
# 릴리스 프로세스
git tag v0.1.0
git push origin v0.1.0
# -> GitHub Actions가 자동으로 빌드, 서명, 업로드
```

각 모듈은 main JAR, sources JAR, javadoc JAR, POM, 그리고 모든 파일에 대한 `.asc` GPG 서명 파일까지 총 8개의 artifact를 생성한다.

## 성능 벤치마크

Quarkus 기반으로 InMemory와 FileStore의 실제 성능을 비교한 결과:

| 지표 | InMemory p50 | InMemory p99 | FileStore p50 | FileStore p99 |
|------|-------------|-------------|---------------|---------------|
| Baseline Ping | 0.83ms | 1.93ms | 0.81ms | 2.33ms |
| Total RTT | 2.45ms | 5.87ms | 3.40ms | 8.35ms |
| Small Message Throughput | 34,108 msg/s | 45,144 msg/s | 24,712 msg/s | 36,643 msg/s |
| Large Message Throughput | 135 msg/s | 148 msg/s | 124 msg/s | 138 msg/s |

FileStore는 InMemory 대비 약 70~80% 수준의 throughput을 보이지만, p50 latency 3.4ms 수준이면 대부분의 실시간 동기화 시나리오에서 충분하다. 디스크 영속성이 필요한 경우 합리적인 트레이드오프다.

## 마무리

durable-streams-java를 만들면서 몇 가지 교훈을 얻었다:

- **프레임워크 비의존적인 프로토콜 엔진을 먼저 만들어라.** `DurableStreamsHandler` 하나에 모든 프로토콜 로직을 집중하고, 어댑터는 최소한의 변환만 수행한다. 새 프레임워크 지원 추가가 수십 줄의 어댑터 코드로 가능하다.
- **Java의 async file I/O는 진짜 async가 아니다.** 벤치마크 없이 NIO async가 더 빠를 것이라고 가정하지 마라. Virtual Threads + Blocking I/O가 더 단순하고 더 빠를 수 있다.
- **OSSRH에서 Maven Central Portal로의 마이그레이션은 생각보다 수월하다.** `nmcp` 플러그인 하나로 대부분 해결된다. 다만 GPG key 관리는 여전히 주의가 필요하다.

프로젝트는 [GitHub](https://github.com/Clickin/durable-streams-java)에서 MIT 라이선스로 공개되어 있다. Maven Central에서 `io.github.clickin` group으로 사용할 수 있다.
